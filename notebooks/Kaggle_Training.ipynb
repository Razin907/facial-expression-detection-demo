{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f4aa7e77",
            "metadata": {},
            "source": [
                "# ðŸŽ­ Facial Expression Detection - Training Notebook\n",
                "\n",
                "**Versi Khusus untuk Dataset dengan Class Imbalance Ekstrem**\n",
                "\n",
                "Dataset Anda memiliki ketidakseimbangan kelas yang parah:\n",
                "- jijik: 436 gambar\n",
                "- senang: 7215 gambar\n",
                "\n",
                "Notebook ini menggunakan **Focal Loss** dan **Class Weights Agresif** untuk mengatasi masalah ini."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "45db9549",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "920eaaaf",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install \"numpy<2.0\" --force-reinstall --upgrade\n",
                "!pip install tensorflow opencv-python matplotlib scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a3e7309b",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import (\n",
                "    Conv2D, MaxPooling2D, Dropout, Flatten, \n",
                "    Dense, BatchNormalization, Activation\n",
                ")\n",
                "from tensorflow.keras.callbacks import (\n",
                "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
                ")\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from sklearn.utils.class_weight import compute_class_weight\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "34c62a24",
            "metadata": {},
            "source": [
                "## 2. Focal Loss (untuk Class Imbalance)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "17717fa7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- FOCAL LOSS ---\n",
                "# Memberikan penalti LEBIH BESAR untuk kesalahan di kelas minoritas\n",
                "\n",
                "def focal_loss(gamma=2.0, alpha=0.25):\n",
                "    def focal_loss_fixed(y_true, y_pred):\n",
                "        epsilon = tf.keras.backend.epsilon()\n",
                "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
                "        \n",
                "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
                "        weight = alpha * y_true * tf.pow(1 - y_pred, gamma)\n",
                "        focal_loss = weight * cross_entropy\n",
                "        \n",
                "        return tf.reduce_sum(focal_loss, axis=-1)\n",
                "    return focal_loss_fixed"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "47b0532c",
            "metadata": {},
            "source": [
                "## 3. Konfigurasi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3be77d27",
            "metadata": {},
            "outputs": [],
            "source": [
                "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
                "\n",
                "if IS_KAGGLE:\n",
                "    DATASET_DIR = '/kaggle/input/ekspresi-wajah1/dataset'\n",
                "    TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
                "    VALIDATION_DIR = os.path.join(DATASET_DIR, 'validation')\n",
                "    MODELS_DIR = '/kaggle/working/models'\n",
                "else:\n",
                "    DATASET_DIR = 'dataset'\n",
                "    TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
                "    VALIDATION_DIR = os.path.join(DATASET_DIR, 'validation')\n",
                "    MODELS_DIR = 'models'\n",
                "\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "MODEL_PATH = os.path.join(MODELS_DIR, 'expression_model.h5')\n",
                "LABELS_PATH = os.path.join(MODELS_DIR, 'class_labels.json')\n",
                "\n",
                "INPUT_SHAPE = (48, 48, 1)\n",
                "NUM_CLASSES = 7\n",
                "\n",
                "print(f\"Environment: {'Kaggle' if IS_KAGGLE else 'Local'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3ebf6d1c",
            "metadata": {},
            "source": [
                "## 4. Data Generators (dengan filter .gitkeep)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "af44c647",
            "metadata": {},
            "outputs": [],
            "source": [
                "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
                "\n",
                "def create_data_generators(train_dir, validation_dir, batch_size=64):\n",
                "    # Augmentasi untuk meningkatkan variasi kelas minoritas\n",
                "    train_datagen = ImageDataGenerator(\n",
                "        rescale=1./255,\n",
                "        rotation_range=15,\n",
                "        width_shift_range=0.15,\n",
                "        height_shift_range=0.15,\n",
                "        shear_range=0.1,\n",
                "        zoom_range=0.1,\n",
                "        horizontal_flip=True,\n",
                "        fill_mode='nearest'\n",
                "    )\n",
                "    \n",
                "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
                "    \n",
                "    # PENTING: classes parameter untuk EXCLUDE .gitkeep\n",
                "    valid_classes = ['marah', 'jijik', 'takut', 'senang', 'netral', 'sedih', 'kaget']\n",
                "    \n",
                "    train_generator = train_datagen.flow_from_directory(\n",
                "        train_dir,\n",
                "        target_size=(48, 48),\n",
                "        batch_size=batch_size,\n",
                "        color_mode='grayscale',\n",
                "        class_mode='categorical',\n",
                "        classes=valid_classes,\n",
                "        shuffle=True\n",
                "    )\n",
                "    \n",
                "    validation_generator = validation_datagen.flow_from_directory(\n",
                "        validation_dir,\n",
                "        target_size=(48, 48),\n",
                "        batch_size=batch_size,\n",
                "        color_mode='grayscale',\n",
                "        class_mode='categorical',\n",
                "        classes=valid_classes,\n",
                "        shuffle=False\n",
                "    )\n",
                "    \n",
                "    return train_generator, validation_generator, valid_classes"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a0b25fa1",
            "metadata": {},
            "source": [
                "## 5. Model (Custom CNN)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8c49ef0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_cnn(input_shape=(48, 48, 1), num_classes=7):\n",
                "    model = Sequential(name='FER_CNN')\n",
                "\n",
                "    # Block 1\n",
                "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "    model.add(Dropout(0.25))\n",
                "\n",
                "    # Block 2\n",
                "    model.add(Conv2D(128, (5, 5), padding='same'))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "    model.add(Dropout(0.25))\n",
                "\n",
                "    # Block 3\n",
                "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "    model.add(Dropout(0.25))\n",
                "\n",
                "    # Block 4\n",
                "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "    model.add(Dropout(0.25))\n",
                "\n",
                "    # Dense\n",
                "    model.add(Flatten())\n",
                "    model.add(Dense(256))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(Dropout(0.25))\n",
                "    \n",
                "    model.add(Dense(512))\n",
                "    model.add(BatchNormalization())\n",
                "    model.add(Activation('relu'))\n",
                "    model.add(Dropout(0.25))\n",
                "\n",
                "    model.add(Dense(num_classes, activation='softmax'))\n",
                "    return model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f6ac8b13",
            "metadata": {},
            "source": [
                "## 6. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9082ac8c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- MAIN TRAINING ---\n",
                "\n",
                "EPOCHS = 80\n",
                "BATCH_SIZE = 64\n",
                "LR = 0.0005\n",
                "\n",
                "if not os.path.exists(TRAIN_DIR):\n",
                "    print(f\"Error: {TRAIN_DIR} tidak ditemukan!\")\n",
                "else:\n",
                "    # 1. Generators\n",
                "    train_gen, val_gen, class_names = create_data_generators(TRAIN_DIR, VALIDATION_DIR, BATCH_SIZE)\n",
                "    \n",
                "    print(f\"\\nClasses: {class_names}\")\n",
                "    print(f\"Train: {train_gen.n} | Val: {val_gen.n}\")\n",
                "    \n",
                "    # 2. Compute Class Weights (AGRESIF)\n",
                "    print(\"\\nMenghitung Class Weights...\")\n",
                "    class_counts = {}\n",
                "    for name in class_names:\n",
                "        path = os.path.join(train_gen.directory, name)\n",
                "        count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.png'))])\n",
                "        class_counts[name] = count\n",
                "        print(f\"  {name}: {count}\")\n",
                "    \n",
                "    labels = []\n",
                "    for idx, name in enumerate(class_names):\n",
                "        labels.extend([idx] * class_counts[name])\n",
                "    \n",
                "    weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
                "    class_weights = {i: w for i, w in enumerate(weights)}\n",
                "    print(f\"\\nClass Weights: {class_weights}\")\n",
                "    \n",
                "    # 3. Create Model\n",
                "    print(\"\\nMembangun Model...\")\n",
                "    model = create_cnn(INPUT_SHAPE, NUM_CLASSES)\n",
                "    \n",
                "    # Compile dengan FOCAL LOSS\n",
                "    model.compile(\n",
                "        optimizer=Adam(learning_rate=LR),\n",
                "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    model.summary()\n",
                "    \n",
                "    # 4. Callbacks\n",
                "    callbacks = [\n",
                "        ModelCheckpoint(MODEL_PATH, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
                "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
                "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=1)\n",
                "    ]\n",
                "    \n",
                "    # 5. Train\n",
                "    print(\"\\nTraining...\")\n",
                "    history = model.fit(\n",
                "        train_gen,\n",
                "        steps_per_epoch=train_gen.n // BATCH_SIZE,\n",
                "        epochs=EPOCHS,\n",
                "        validation_data=val_gen,\n",
                "        validation_steps=val_gen.n // BATCH_SIZE,\n",
                "        callbacks=callbacks,\n",
                "        class_weight=class_weights,\n",
                "        verbose=1\n",
                "    )\n",
                "    \n",
                "    # 6. Plot\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "    axes[0].plot(history.history['accuracy'], label='Train')\n",
                "    axes[0].plot(history.history['val_accuracy'], label='Val')\n",
                "    axes[0].set_title('Accuracy')\n",
                "    axes[0].legend()\n",
                "    axes[0].grid(True, alpha=0.3)\n",
                "    \n",
                "    axes[1].plot(history.history['loss'], label='Train')\n",
                "    axes[1].plot(history.history['val_loss'], label='Val')\n",
                "    axes[1].set_title('Loss')\n",
                "    axes[1].legend()\n",
                "    axes[1].grid(True, alpha=0.3)\n",
                "    plt.show()\n",
                "    \n",
                "    # 7. Save labels\n",
                "    labels_dict = {i: name for i, name in enumerate(class_names)}\n",
                "    with open(LABELS_PATH, 'w') as f:\n",
                "        json.dump(labels_dict, f, indent=2)\n",
                "    print(f\"\\nModel: {MODEL_PATH}\")\n",
                "    print(f\"Labels: {LABELS_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3905713f",
            "metadata": {},
            "source": [
                "## 7. Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3e00e6cf",
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import FileLink\n",
                "\n",
                "if os.path.exists(MODEL_PATH):\n",
                "    display(FileLink(MODEL_PATH))\n",
                "    display(FileLink(LABELS_PATH))\n",
                "else:\n",
                "    print(\"Model belum tersedia.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
